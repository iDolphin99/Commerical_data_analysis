{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40dea94",
   "metadata": {},
   "source": [
    "# Data Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy import stats #Analysis \n",
    "from scipy.stats import norm \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf375d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트가 깨지면 실행하세요! \n",
    "import matplotlib.font_manager as fm\n",
    "fontlist = fm.findSystemFonts(fontpaths = None, fontext='ttf')\n",
    "# 아래 주석을 지워서 폰트 리스트를 확인하고 한글 폰트를 font_path에 추가합니다\n",
    "fontlist[:]\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "#font_path = 'C:\\\\Users\\\\mtang\\\\AppData\\\\Local\\\\Microsoft\\\\Windows\\\\Fonts\\\\NanumSquare.ttf'\n",
    "font_path = 'C:\\\\WINDOWS\\\\Fonts\\\\NanumGothicLight.ttf'\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68108247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas option 설정 하는 코드\n",
    "# monthly_gain의 경우 부동소수점으로 나타나서 보기 어려울땐 윗 줄의 주석을 제거하고 아래에 주석을 추가하고\n",
    "# 다시 원래대로 돌리고 싶다면 아래에 주석제거, 위 코드에 주석추가\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "#pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Dataset/\"\n",
    "\n",
    "data = pd.read_csv(path+\"kwproja_data_location.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eecf56c",
   "metadata": {},
   "source": [
    "# 2. EDA \n",
    "\n",
    "2,927,739 rows X 11 columns\n",
    "\n",
    "- 매장 속성 정보\n",
    "  - shop_code -> 식별자 feature => drop   \n",
    "  - shop_name => DL\n",
    "  - longtitude : 경도, latitude : 위도 -> 매장 위치 (회사 근처, 학교 근처 등 매출 영향성 있음) -> K-mean clustering => geo, ML, DL\n",
    "  - address1, address2 : GeoEncoder를 통해 따로 얻은 행정동, 1(30), 2(436) => DL\n",
    "  - shop_type_big -> 15 category, shop_type_big_label, ML => DL\n",
    "  - shop_type_small -> 61 category, shop_type_small_label, ML => DL \n",
    "\n",
    "- 매출 정보\n",
    "  - date -> 24 category, 201606~ 201805 까지의 data\n",
    "  - monthly_gain / avearge_sale_price = 한달 총 판매수\n",
    "\n",
    "- 매출 통계 정보-> X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename data columns and check the data\n",
    "data.columns = ['date', 'shop_code', 'shop_name', 'shop_type_big', 'shop_type_small', \n",
    "                'longitude', 'latitude', 'monthly_gain', 'average_sale_price', 'address1', 'address2']\n",
    "\n",
    "print(data.columns, '\\n')\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042f77d",
   "metadata": {},
   "source": [
    "# 3. Preprocessing \n",
    "- df_geo : 구(address1)를 기준으로 통계량을 붙여놓은 데이터프레임 \n",
    "    - monthly_gain + average_sale_price + shop_type_big 개수 \n",
    "    - count : 데이터 개수 \n",
    "    - mg : monthly_gain 약자 \n",
    "    - sp : average_sale_price 약자 \n",
    "    - mean, st, ~ max : 평균값, 표준편차, ~ 최대값 \n",
    "    - shop_type_big(15) : 각 업종대분류에 해당하는 데이터가 해당 지역(구)에는 몇 개가 있는가? \n",
    "    - 0, 1, 2 : 각 구마다 1등, 2등, 3등으로 많은 업종 대분류는? \n",
    "    - **27 rows × 34 columns**\n",
    "- df_shop : 업종 대분류(shop_type_big)을 기준으로 통계량을 붙여놓은 데이터프레임 \n",
    "    - **15 rows × 49 columns**\n",
    "- 구 -> label encoder => (30개)\n",
    "    - '강남구' '강동구' '강북구' '강서구' '고양시 덕양구' '과천시' '관악구' '광명시' '광진구' '구로구' '구리시'\n",
    "      '금천구' '노원구' '도봉구' '동대문구' '동작구' '마포구' '서대문구' '서초구' '성동구' '성북구' '송파구' '양천구'\n",
    "      '영등포구' '용산구' '은평구' '종로구' '중구' '중랑구' '하남시' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45638d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 data와 따로 관리 -> original data = data, preprocessed data = processed_data \n",
    "processed_data = data.copy()\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4967e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data['average_sale_price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b631baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot 상 outlier와 Quantile 상 75% 이상의 값을 확인합니다\n",
    "# we detect outlier (from upper, lower) and values greater than 75% in the quantile\n",
    "\n",
    "Q1 = processed_data['average_sale_price'].quantile(0.25)\n",
    "Q3 = processed_data['average_sale_price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_fence = Q1 - (1.5 * IQR)\n",
    "upper_fence = Q3 + (1.5 * IQR)\n",
    "\n",
    "upper = processed_data[processed_data['average_sale_price'] >= upper_fence]['average_sale_price']\n",
    "upper_10 = processed_data[processed_data['average_sale_price'] >= 1000000]['average_sale_price']\n",
    "lower = processed_data[processed_data['average_sale_price'] <= lower_fence]['average_sale_price']\n",
    "#upper = processed_data[processed_data['average_sale_price'] >= upper_fence]['average_sale_price']\n",
    "print(processed_data['average_sale_price'].max())\n",
    "\n",
    "print(upper_fence)\n",
    "print(lower_fence)\n",
    "print(processed_data['average_sale_price'].min())\n",
    "print()\n",
    "print()\n",
    "print(processed_data['average_sale_price'].quantile(0.5))\n",
    "print(len(upper))\n",
    "print(len(lower))\n",
    "\n",
    "#print(\"%.2f \\t\" % upper_fence, len(df[df > upper_fence]),\n",
    "#          \"\\t %.2f \\t\" % lower_fence, len(df[df < lower_fence]),\n",
    "#          \"\\t %.2f \\t\" % list_q4, len(df[df > list_q4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7faf0",
   "metadata": {},
   "source": [
    "### geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed766e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly_gain \n",
    "group1 = processed_data[['monthly_gain', 'address1']].groupby('address1')\n",
    "df1 = group1.describe().droplevel(axis=1, level=0)\n",
    "\n",
    "# round\n",
    "df1.iloc[:, 1:] = df1.iloc[:, 1:].applymap(lambda x : round(x, -4))\n",
    "df1.columns = ['count', 'mean_mg', 'st_mg', 'min_mg', '25%_mg', '50%_mg', '75%_mg', 'max_mg']\n",
    "\n",
    "# sum - 총 매출\n",
    "df1['monthly_gain'] = group1.sum().apply(lambda x : round(x, -4))\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8583698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_sale_price\n",
    "df2 = processed_data[['average_sale_price', 'address1']].groupby('address1')\n",
    "df2 = df2.describe().droplevel(axis=1, level=0)\n",
    "\n",
    "# round\n",
    "df2.iloc[:, 1:] = df2.iloc[:, 1:].applymap(lambda x : round(x, -4))\n",
    "df2.columns = ['count', 'mean_sp', 'st_sp', 'min_sp', '25%_sp', '50%_sp', '75%_sp', 'max_sp']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059804e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shop_type_big\n",
    "df3 = processed_data.groupby(['address1', 'shop_type_big']).size()\n",
    "df3 = df3.unstack() # unstack : SQL 집계 결과를 가로, 세로 축으로 보기 좋게 나열 \n",
    "df3 = df3.fillna(0) # NaN to 0\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738de6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank for shop_type_big\n",
    "df4 = df3.apply(lambda s, n: pd.Series(s.nlargest(n).index), axis=1, n=3)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = pd.concat([df1, df2.iloc[:, 1:]], axis=1)\n",
    "df_geo = pd.concat([df_geo, df3], axis=1)\n",
    "df_geo = pd.concat([df_geo, df4], axis=1)\n",
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.to_csv('df_geo.csv', float_format = '%.2f', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f396274",
   "metadata": {},
   "source": [
    "### geo - date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e179350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date \n",
    "df5 = processed_data[['date', 'address1', 'monthly_gain']].groupby(['address1', 'date']).mean().round(-4)\n",
    "df6 = processed_data[['date', 'address1', 'monthly_gain']].groupby(['address1', 'date']).count()\n",
    "\n",
    "df5 = df5.unstack()\n",
    "df5 = df5.rename(columns = {'monthly_gain' : 'mean'})\n",
    "df6 = df6.unstack()\n",
    "df6 = df6.rename(columns = {'monthly_gain' : 'count'})\n",
    "\n",
    "df_geo_date = pd.concat([df5, df6], axis=1)\n",
    "df_geo_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f0dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo_date.to_csv('df_geo_date.csv', float_format = '%.2f', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d275162",
   "metadata": {},
   "source": [
    "### shop type big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79760471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly_gain \n",
    "group1 = processed_data[['monthly_gain', 'shop_type_big']].groupby('shop_type_big')\n",
    "df1 = group1.describe().droplevel(axis=1, level=0)\n",
    "\n",
    "df1.iloc[:, 1:] = df1.iloc[:, 1:].applymap(lambda x : round(x, -4))\n",
    "df1.columns = ['count', 'mean_mg', 'st_mg', 'min_mg', '25%_mg', '50%_mg', '75%_mg', 'max_mg']\n",
    "\n",
    "# sum - 총 매출\n",
    "df1['monthly_gain'] = group1.sum().apply(lambda x : round(x, -4))\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_sale_price\n",
    "df2 = processed_data[['average_sale_price', 'shop_type_big']].groupby('shop_type_big')\n",
    "df2 = df2.describe().droplevel(axis=1, level=0)\n",
    "\n",
    "df2.iloc[:, 1:] = df2.iloc[:, 1:].applymap(lambda x : round(x, -4))\n",
    "df2.columns = ['count', 'mean_sp', 'st_sp', 'min_sp', '25%_sp', '50%_sp', '75%_sp', 'max_sp']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9fc062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# address1 - geo\n",
    "df3 = processed_data.groupby(['shop_type_big', 'address1']).size()\n",
    "df3 = df3.unstack() # unstack : SQL 집계 결과를 가로, 세로 축으로 보기 좋게 나열 \n",
    "df3 = df3.fillna(0) # NaN to 0\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e7420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank for address1(geo)\n",
    "df4 = df3.apply(lambda s, n: pd.Series(s.nlargest(n).index), axis=1, n=3)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa4f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_type = pd.concat([df1, df2.iloc[:, 1:]], axis=1)\n",
    "df_type = pd.concat([df_type, df3], axis=1)\n",
    "df_type = pd.concat([df_type, df4], axis=1)\n",
    "df_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf38dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17fa15e",
   "metadata": {},
   "source": [
    "### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4851af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = processed_data[['monthly_gain', 'average_sale_price']].describe().transpose()\n",
    "\n",
    "# round - except for min, count \n",
    "df_total.iloc[:, 1:3] = df_total.iloc[:, 1:3].applymap(lambda x : round(x,  -4))\n",
    "df_total.iloc[:, 4:] = df_total.iloc[:, 4:].applymap(lambda x : round(x,  -4))\n",
    "\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mg = processed_data['monthly_gain'].sum().round(-4)\n",
    "sum_sp = processed_data['average_sale_price'].sum().round(-4)\n",
    "\n",
    "df_total[\"sum\"] = [sum_mg, sum_sp]\n",
    "\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70adf08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv('df_total.csv', float_format = '%.2f', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a30f2",
   "metadata": {},
   "source": [
    "### shop_name + shop_type_big + shop_type_small : df_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58759210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP용 preprocessing \n",
    "# shop_name, shop_type_big, shop_type_small = concat_text \n",
    "df_nlp1 = processed_data.copy()\n",
    "df_nlp1['concat_text'] = df_nlp1['shop_name'] + ' ' + df_nlp1['shop_type_big'] + ' ' + df_nlp1['shop_type_small'] + ' '\n",
    "df_nlp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51922e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp2 = df_nlp1[['concat_text', 'address1']]\n",
    "df_nlp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939061ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "df_nlp = pd.DataFrame()\n",
    "alist = df_nlp2['address1'].unique()\n",
    "for add in alist : \n",
    "    tk = Tokenizer()\n",
    "    tk.fit_on_texts(df_nlp2[df_nlp2['address1'] == add]['concat_text'])\n",
    "    \n",
    "    wordlist = sorted(tk.word_counts.items(), key=lambda x: x[1], reverse=True)[:30]\n",
    "    df_word = pd.DataFrame(wordlist)\n",
    "    df_nlp = pd.concat([df_nlp, df_word], axis=1)\n",
    "    \n",
    "    print(add, \": \", list(wordlist))\n",
    "    print(\"\\nvocab words 개수 : \", len(tk.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ad423",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = list(df_nlp.columns)\n",
    "cnt = 0\n",
    "for i in range (len(cols_list)) :\n",
    "    if i%2 == 0 : \n",
    "        cols_list[i] = alist[cnt]\n",
    "        cnt = cnt + 1 \n",
    "    else : \n",
    "        cols_list[i] = str(alist[cnt-1]) + \" counts\"\n",
    "df_nlp.columns = cols_list\n",
    "df_nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0919f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42afd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp.to_csv('df_nlp.csv',encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf67e4f",
   "metadata": {},
   "source": [
    "### shop_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa486b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP용 preprocessing \n",
    "# shop_name, shop_type_big, shop_type_small = concat_text \n",
    "df_nlp1 = processed_data.copy()\n",
    "df_nlp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a63b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "df_nlp = pd.DataFrame()\n",
    "alist = df_nlp1['address1'].unique()\n",
    "for add in alist : \n",
    "    tk = Tokenizer()\n",
    "    tk.fit_on_texts(df_nlp1[df_nlp1['address1'] == add]['shop_name'])\n",
    "    \n",
    "    wordlist = sorted(tk.word_counts.items(), key=lambda x: x[1], reverse=True)[:30]\n",
    "    df_word = pd.DataFrame(wordlist)\n",
    "    df_nlp = pd.concat([df_nlp, df_word], axis=1)\n",
    "    \n",
    "    print(add, \": \", list(wordlist))\n",
    "    print(\"\\nvocab words 개수 : \", len(tk.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = list(df_nlp.columns)\n",
    "cnt = 0\n",
    "for i in range (len(cols_list)) :\n",
    "    if i%2 == 0 : \n",
    "        cols_list[i] = alist[cnt]\n",
    "        cnt = cnt + 1 \n",
    "    else : \n",
    "        cols_list[i] = str(alist[cnt-1]) + \" counts\"\n",
    "df_nlp.columns = cols_list\n",
    "df_nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9293d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a79bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp.to_csv('df_shopname.csv',encoding = 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
