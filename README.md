# Commerical_data_analysis_AI
Commercial location recommend system using Deep Learning data analysis  
ë”¥ëŸ¬ë‹ ë°ì´í„° ë¶„ì„ì„ í†µí•œ ìµœì ì˜ ìƒê¶Œì…ì§€ ì¶”ì²œ ê¸°ìˆ  ê°œë°œ

### ğŸ› ï¸ **Specification**
<p>
  <img src="https://img.shields.io/badge/Python-3766AB?style=flat-square&logo=Python&logoColor=white"/></a>&nbsp   
  <img src="https://img.shields.io/badge/Pandas-150458?style=flat-square&logo=pandas&logoColor=white"/></a>&nbsp 
  <img src="https://img.shields.io/badge/Scikit Learn-F7931E?style=flat-square&logo=scikitlearn&logoColor=white"/></a>&nbsp 
  <img src="https://img.shields.io/badge/Keras-D00000?style=flat-square&logo=keras&logoColor=white"/></a>&nbsp
  <img src="https://img.shields.io/badge/TensorFlow-F7931E?style=flat-square&logo=tensorflow&logoColor=white"/></a>&nbsp 
  <img src="https://img.shields.io/badge/Git-F05032?style=flat-square&logo=Git&logoColor=white"/></a>&nbsp 
  <img src="https://img.shields.io/badge/Jupyter-F37626?style=flat-square&logo=jupyter&logoColor=white"/></a>&nbsp
  <br/>
  <img src="https://img.shields.io/badge/HTML5-E34F26?style=flat-square&logo=html5&logoColor=white"/></a>&nbsp 
  <img src="https://img.shields.io/badge/CSS3-1572B6?style=flat-square&logo=css3&logoColor=white"/></a>&nbsp 
  <img src="https://img.shields.io/badge/JavaScript-ffb13b?style=flat-square&logo=javascript&logoColor=white"/></a>&nbsp
  <img src="https://img.shields.io/badge/Node.js-339933?style=flat-square&logo=nodedotjs&logoColor=white"/></a>&nbsp
  <img src="https://img.shields.io/badge/Socket.io-010101?style=flat-square&logo=socketdotio&logoColor=white"/></a>&nbsp
  <img src="https://img.shields.io/badge/JSON-000000?style=flat-square&logo=json&logoColor=white"/></a>&nbsp
  <img src="https://img.shields.io/badge/Oracle-F80000?style=flat-square&logo=oracle&logoColor=white"/></a>&nbsp
  <img src="https://img.shields.io/badge/Docker-2496ED?style=flat-square&logo=docker&logoColor=white"/></a>&nbsp
  <img src="https://img.shields.io/badge/AWS-232F3E?style=flat-square&logo=amazonaws&logoColor=white"/></a>&nbsp
  <img src="https://img.shields.io/badge/Ubuntu-E95420?style=flat-square&logo=ubuntu&logoColor=white"/></a>&nbsp
  <img src="https://img.shields.io/badge/MacOS-000000?style=flat-square&logo=apple&logoColor=white"/></a>&nbsp
</p>

### ğŸ† **Award**
We got a prize for excellence in the spring academic conference, ASK 2022, ì‚°í•™í˜‘ë™ìš°ìˆ˜ìƒğŸ‰  
We got a prize for excellence in the KW & SW exhibition, Industry-Academic Collaboration SW Project, ìµœìš°ìˆ˜ìƒğŸ‰  
We got a prize for excellence in the KW University graduation exhibition, 3rd Prize, ì¥ë ¤ìƒğŸ‰  

### ğŸš© **Demo**
[![Image](https://user-images.githubusercontent.com/78654870/175818055-320a7c87-019a-4ba1-bea0-53424c7e9b61.png)](https://www.youtube.com/watch?v=WBNOciDR3Zw)

<br>

## ğŸ” Overview 

1. [Goal](https://github.com/iDolphin99/Commerical_data_analysis#-1-goal)
2. [EDA & Preprocessing](https://github.com/iDolphin99/Commerical_data_analysis#-2-eda--preprocessing)
3. [Regression](https://github.com/iDolphin99/Commerical_data_analysis#-3-regression)
4. [Classfication](https://github.com/iDolphin99/Commerical_data_analysis#-4-multi-class-classification)
5. [Deep Learning](https://github.com/iDolphin99/Commerical_data_analysis#-5-deep-learning)
6. [Score](https://github.com/iDolphin99/Commerical_data_analysis#-6-score)
7. [Platform](https://github.com/iDolphin99/Commerical_data_analysis#-7-platform) 
8. [Rule](https://github.com/iDolphin99/Commerical_data_analysis#-8-rule)
9. [Team Members](https://github.com/iDolphin99/Commerical_data_analysis#%EF%B8%8F-9-team-members)

<br>

## ğŸ¯ 1. Goal
Hello there ğŸ‘‹

This repository is for our awesome Industry-Academy Collaboration Project.
This would be helpful if you have some problems like **'how to deal with extreme skewed-data'** or **'how to solve regression problem with classification method'** and so on. We tried to write everything we experimented as much as possible. We hope even these attempts could help you.

We aim to develop **a system that recommends the best commercial location using machine learning and deep learning approach based on a large amount of commercial location data.** To do this, we train model to predict **'monthly gain'** of each stores. In addition we create **Web dashboard** to visualize our insights of huge commercial location data obtained in the project and add a short simulation function using the trained model. Finally, we wish this system help some small business owners who start their own businesses and want to increase their sales. ğŸ™Œ

<br> 

## ğŸ“Œ 2. EDA & Preprocessing 
See our **EDA_report_code.ipynb** code. ('bd' means 'big data', and 'sd' means 'sample data' ğŸ˜)

The biggest problem in our data is that **it has large deviations and strong biases, skewness.** The monthly sales earned by each stores are too different and data should be pre-processed to help models predict this huge values well. 

We received two types of data, so there're two versions for EDA code. But we fianlly used version of big data to train models. It is important to apply appropriate preprocessing techniques for each data. So we have summarized the methods that we applied below and if you get more details about preprocessing techniques we used, please take a look for baseline code, especially markdown part. We have written in more detail there. 

- Removing missing values
- **Feature Selection** 
  - Drop unnecessary columns like identifier, shop code feature
- **Encoding** 
  - It is important to use appropriate encoding methods for categorical variables! 
  - Both ways were effective, but we we finally use binary encoder, for the reason that binary encoder does not give oridinality to categorical variables
  - Label Encoding 
  - Binary Encoding 
- **K-mean Clustering** 
  - Combined "latitude" and "longitude" to create a new feature "geo"
  - Use k++ method
  - k=9 is optimal number of clusters based on Silhouette Coefficient
- **Log Transformation** 
  - Log transform is very important in making a strongly right-skewed distribution follow a normal distribution
  - we also experimented scaler like MinMax, Normalization, Robust, Standard, but all of them were failed
- **Removing Outlier** 

<br>

## ğŸš€ 3. Regression 
Usually, problems such as prdicting home prices or stock prices use a regression approach. So we also start with regression models and compared them. What we get attention is that the error rate of all models decreased by about 60% on average after the outlier was removed. 

Despite various attempts, there were clear limitations to regression method. 
- **K-Fold Cross-Validation**
  - Use k=5
- Log transformation <-> backtoOriginal
  - but the performance has fallen further 
- **Hyperparameter tuning**
  - Use GridSearchCV 
  - LGBM -> objective = tweedie, tweedie loss function => but there was a limiation to improving preformance more highter
- New Evaluation Metrics
- LightGBM for Quantile Regression

#### Model
- Gradient Boosting model
  - XGB, LGBM 
- Regularized Linear model
  - Ridge, Lasso
#### Evaluation metrics
- MSE, RMSE 
- adjusted R2  
  - you need more information about adjusted r2 score, check [this](https://www.inflearn.com/questions/48025)
#### BenchMark   
From left side, three columns mean **"For sample data", "For big data"** values we measured. Seeing 'for big data' figure is enough. 

  | Model |            MSE          |     RMSE    |  adj R2  |        MSE        |    RMSE    |  adj R2  | 
  |-------|:------------------------|:------------|:---------|:------------------|:-----------|:---------|
  |  XGB  |  84,552,727,800,574,600 |  287561374  |   0.88   |167,212,972,899,818| 12,931,085 |    0.3   | 
  | LGBM  | 104,100,031,628,893,000 |  318634288  |   0.87   |170,001,344,508,730| 13,038,456 |    0.2   | 
  | Ridge |                         |             |          |218,298,021,558,504| 14,774,911 |   0.14   | 
  | Lasso |                         |             |          |218,298,022,158,726| 14,774,911 |   0.14   | 

<br>

## ğŸš€ 4. Multi-Class Classification
To solve the regression problem as a classification problem, it depends on **labeling the y variable, 'monthly gain'.** We exprienced with many various ideas and were able to achieve the Robust results when using Quantile. In particular, we can obtain the best results because we applied method according to the deviation of each shop type big. 
- Goal : **How to label(or classify) our skewed y data as many labels as possible and high accuracy?** 
  - **Labeling 1** : Cut a specific range like 10%, 20%, 33%, 50%.. from the front in order 
  - **Labeling 2** : Divide into lower fence, Q2, and upper fence values using quantiles 
  - **Labeling 3** : Divide into Q1, Q2 and Q3 values using quantiles
  - **Labeling 4** : Divide between minimum and maximum as heuristic (more detailed in 10 ~ 30 million won, other than sparsely)
  - Using mean, std for labeling, but we got the worst result from this method ğŸ¤” 
  - Rounding the values to make it easier to read, but it didn't mean much just for understanding 

#### Model
- Gradient Boosting model 
  - XGB, LGBM
#### Evaluation metrics
- Accuracy, Precision, Recall, F1 score 
#### BenchMark   
We only write accuracy score below. And as shown in the table, Labeling 3 method was the best. 

  |            |  Label |  XGB  |  LGBM  |                                   Description                             |
  |------------|:-------|:------|:-------|:--------------------------------------------------------------------------|
  | Labeling 1 |   10   |  0.22 |  0.21  |Categorized by specific ranges (10%, 20%, 33%) in order from small to large|
  | Labeling 2 |   31   |  0.57 |  0.30  |       (Quantile) Categorized by Lower Fence, Q2, and Upper Fence          |
  | Labeling 3 |   45   |  0.58 |  0.11  |                (Quantile) Categorized by Q1, Q2, and Q3                   |
  | Labeling 4 |   12   |  0.35 |  0.33  |             Categorized between min and max values of data                |
      
<br>

## ğŸš€ 5. Deep Learning 
More higher performance and learning data from differenct perspectives, we trained Deep Learining model, especiall NLP(Natural Langauge Processing) techniques. To build NLP model, we used Sequential Model of Keras Library and created a new natural language variable from our data to obtain a totla of 120,000 word datasets.  

![16](https://user-images.githubusercontent.com/78654870/170285957-0ffa956c-493d-4828-943d-6aaa26569217.png)

<br>

## ğŸ“ˆ 6. Score
The machine learning model learned various variables such as geo, average sale price, shop type and the deep learning model learned natural language meanings. We checked prediction accuracy when two models learned from different perspectives were properly ensembled, and we write each results below. To sum up, We finally got 0.83 acc! ğŸ‘ğŸ‘ğŸ‘

  |         Model        |  Accuracy | 
  |----------------------|:----------|
  |  XGB Classifier(ML)  |   0.58    |
  | Sequential Model(DL) |   0.81    | 
  | **0.5 ML + 0.5 DL**  |  **0.83** | 
  
<br>

## ğŸš€ 7. Platform
#### 0. ê°œë°œí™˜ê²½
  + OS : Ubuntu
  + DBMS : Oracle 11g/xe
  + Backend : Javascript (Node.js)
  + Front : HTML, CSS, Javascript
  
#### 1. OpenK 
<div>&nbsp;&nbsp;&nbsp;&nbsp;<img width="100" alt="image" src="https://user-images.githubusercontent.com/90493141/170158089-300182ac-eee0-483e-9986-702ad5659b77.png"></div><br/>

  + Mean : ë§ì€ ì •ë³´ë“¤ì´ ëª¨ì—¬ í•˜ë‚˜ì˜ ê²°ê³¼ë¥¼ ì œê³µ
  + Purpose : ìƒê¶Œì…ì§€ ì •ë³´ì™€ ë§¤ì¶œ ì •ë³´ë¥¼ ì‰½ê²Œ ì•Œì•„ë³¼ ìˆ˜ ìˆëŠ” Web DashBoard ì œì‘

#### 2. Category 
  + ìƒì ë³„ (ì„œìš¸ ë‚´ ìƒì ë³„ ë§¤ì¶œ ì •ë³´)
    <br/><div><img width="800" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-05-25 á„‹á…©á„Œá…¥á†« 10 37 16" src="https://user-images.githubusercontent.com/90493141/170160344-7351fbc6-78d7-4b1d-80dd-525c6980feb2.png"></div>
    
    + ì‚¬ìš©ë²• : 
      1) ì›í•˜ëŠ” ì§€ì—­ & ì—…ì¢… í•„í„°ë¥¼ ì„ íƒ
      2) í•„í„°ë§ í›„ ì§€ë„ìƒì— í‘œì‹œëœ í•€ë“¤ ì¤‘ ì›í•˜ëŠ” ìƒì ì˜ í•€ì„ ì„ íƒ
      3) ì„ íƒëœ ìƒì  ì •ë³´ (ìƒì  ë§¤ì¶œ ì •ë³´) í™•ì¸
    + ë°ì´í„° ì •ë³´ :
      + í•€ : ê° ìƒì ì˜ ìœ„ë„&ê²½ë„ë¥¼ í™œìš©í•´ ì§€ë„ìƒì— í•€ìœ¼ë¡œ í‘œì‹œí•˜ê³ , í•€ ì•ˆì˜ ë‚´ìš©ì€ í•´ë‹¹ ìƒì ì˜ í‰ê·  ë§¤ì¶œ
      + í•„í„°ë§ : ì›í•˜ëŠ” ì—…ì¢… & ì§€ì—­ìœ¼ë¡œ í•„í„°ë§í•˜ì—¬ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¡°ê±´ì˜ ìƒì ë“¤ì„ ì§€ë„ìƒì— í‘œì‹œí•´ì£¼ëŠ” ê¸°ëŠ¥
        + í•„í„° ì—†ìŒ : (í–‰ì •êµ¬+í–‰ì •ë™)Ã—(ì—…ì¢…ëŒ€ë¶„ë¥˜+ì—…ì¢…ì†Œë¶„ë¥˜)ì˜ ì¢…ë¥˜ë³„ë¡œ ê°€ì¥ ìµœì‹  ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ìƒì 
        + ì—…ì¢… : ì—…ì¢…ëŒ€ë¶„ë¥˜ì™€ ì—…ì¢…ì†Œë¶„ë¥˜(ìˆ«ì)ë¥¼ ì„ íƒí–ˆì„ ê²½ìš° ì„ íƒëœ ì—…ì¢…ìœ¼ë¡œ ìƒì  í•„í„°ë§
        + ì§€ì—­ : í–‰ì •êµ¬ì™€ í–‰ì •ë™ì„ ì„ íƒí–ˆì„ ê²½ìš° ì„ íƒëœ ì§€ì—­ìœ¼ë¡œ ìƒì  í•„í„°ë§
        + ì—…ì¢…+ì§€ì—­ : ì§€ì—­ê³¼ ì—…ì¢… í•„í„°ë¥¼ ë™ì‹œì— ì„ íƒí–ˆì„ ê²½ìš°
      + ìƒì  ì •ë³´ : ì„ íƒëœ í•€(ìƒì )ì˜ ë§¤ì¶œ ì •ë³´
        + ìƒì  ì´ë¦„ : ì„ íƒëœ ìƒì  ì´ë¦„ (ê°œì¸ì •ë³´ìƒ ì¼ë¶€ ì œê³µ)
        + ì—…ì¢… : ì„ íƒëœ ìƒì ì˜ ì—…ì¢… ì½”ë“œ (ì—…ì¢…ëŒ€ë¶„ë¥˜+ì—…ì¢…ì†Œë¶„ë¥˜)
        + ìœ„ì¹˜ : ì„ íƒëœ ìƒì ì˜ ìœ„ë„ & ê²½ë„ ê¸°ë°˜ ì£¼ì†Œ (ë„ë¡œëª…+í–‰ì •ì£¼ì†Œ & ì§€ë²ˆ+í–‰ì •ì£¼ì†Œ)
        + ì›”ë³„ ë§¤ì¶œ : ì„ íƒëœ ìƒì ì˜ ì›”ë³„ ë§¤ì¶œ
        + ë‹¤ìŒë‹¬ ë§¤ì¶œ ì˜ˆì¸¡ : ì‚¬ìš©ìê°€ ë‹¨ê°€ë¥¼ ì¡°ì •í•˜ì—¬ ê°€ì¥ ìµœê·¼ ë‹¬ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒ ë‹¬ì˜ ë§¤ì¶œì„ ì˜ˆì¸¡í•´ì£¼ëŠ” ì‹œìŠ¤í…œ
        
  + ì§€ì—­ë³„ (ì„œìš¸ êµ¬ë³„ ë§¤ì¶œ ì •ë³´)
     <br/><div><img width="800" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-05-25 á„‹á…©á„Œá…¥á†« 10 07 32" src="https://user-images.githubusercontent.com/90493141/170157138-25c2fb62-b0ae-41ae-83d0-e935e57d1e2d.png"></div>

    + ì‚¬ìš©ë²• : ì„œìš¸ êµ¬ ì§€ë„ë¥¼ í†µí•´ ë³´ê³ ì‹¶ì€ êµ¬ë¥¼ í´ë¦­í•˜ì—¬ í•´ë‹¹ êµ¬ì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„° í™•ì¸
    + ë°ì´í„° ì •ë³´ : 
      + ë§¤ì¶œ ì •ë³´ : ì„ íƒëœ êµ¬ì˜ ë§¤ì¶œ ì •ë³´ (ì„œìš¸ ì „ì²´ êµ¬ ë§¤ì¶œ ìˆœìœ„, êµ¬ë‚´ ìƒì  í‰ê·  ë§¤ì¶œ, êµ¬ë‚´ ìƒì  ìµœëŒ€ ë§¤ì¶œ)
      + ë§¤ì¶œ ë¹„êµ : ì„ íƒëœ êµ¬ì™€ ì„œìš¸ ì „ì²´ ë§¤ì¶œ ë¹„êµ (êµ¬ë‚´ ìƒì  í‰ê·  ë§¤ì¶œ, êµ¬ë‚´ ìƒì  ìµœëŒ€ ë§¤ì¶œ, êµ¬ë‚´ ìƒì  ì›”ë³„ í‰ê·  ë§¤ì¶œ)
      + ì¸ê¸° ì—…ì¢… : ì„ íƒëœ êµ¬ì˜ êµ¬ë‚´ ì¸ê¸° ì—…ì¢… TOP3
      + ì¸ê¸° í‚¤ì›Œë“œ : ì„ íƒëœ êµ¬ì˜ êµ¬ë‚´ ìƒì  ì´ë¦„ & ì—…ì¢… ê¸°ë°˜ ì¸ê¸° í‚¤ì›Œë“œ
      
  + ë©”ë‰´ì–¼ (ë§¤ì¶œ ë°ì´í„°ê°€ ì–´ë ¤ìš´ ì‚¬ìš©ìë“¤ì„ ìœ„í•œ ê¸°ëŠ¥)
    <br/><div><img width="800" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-05-25 á„‹á…©á„Œá…¥á†« 10 15 03" src="https://user-images.githubusercontent.com/90493141/170157818-1b0615ff-7c97-47c3-b2b4-e4c482b3b8ae.png"></div>
    
    + ì‚¬ìš©ë²• : ì›¹ í˜ì´ì§€ ë‚´ ìš°ì¸¡ í•˜ë‹¨ì˜ ì›í˜• ë²„íŠ¼ í´ë¦­
    + ëª©ì  : XAIê´€ì ì—ì„œ ë§¤ì¶œ ì˜ˆì¸¡ ë°ì´í„°ê°€ ë‚˜ì˜¤ê²Œ ëœ ë°°ê²½ì— ëŒ€í•œ ë©”ë‰´ì–¼ ì œê³µ

#### 3. ì°¸ê³  ë¬¸ì„œ
  + í–‰ì • ìë©´ë™ ê²½ê³„ : https://github.com/vuski/admdongkor/blob/master/ver20220309/ver20220309_emd_vote_simple.geojson
  + ì„œìš¸ êµ¬ ì§€ë„ : https://upload.wikimedia.org/wikipedia/commons/2/2c/01-00-seoul-ko.svg
 
<br>

## ğŸ“ 8. Rule 
- Please create your own folder and branch with your nickname and work on there. We use 'master' branch as main branch. 
- Take care about the data leakage. The data will be discarded after the project is completed. 
- ê°ìì˜ ë‹‰ë„¤ì„ìœ¼ë¡œ ëœ folderë¥¼ ë§Œë“¤ì–´ì„œ, branchë¥¼ ë”´ í›„ ì‘ì—…í•´ì£¼ì„¸ìš”. main branch ì´ë¦„ì€ masterë¡œ ì§€ì •í•©ë‹ˆë‹¤. 
- ë°ì´í„° ìœ ì¶œì— ì£¼ì˜í•´ì£¼ì„¸ìš”. í”„ë¡œì íŠ¸ê°€ ì¢…ë£Œëœ í›„ ë°ì´í„°ëŠ” íŒŒê¸°í•©ë‹ˆë‹¤. 

<br>

## ğŸ™‹â€â™‚ï¸ 9. Team members
[<img src="https://avatars.githubusercontent.com/u/78654870?v=4" width="200px">](https://github.com/iDolphin99)|[<img src="https://avatars.githubusercontent.com/u/49301413?v=4" width="230px;" alt=""/>](https://github.com/yoonbincho) |[<img src="https://avatars.githubusercontent.com/u/90493141?v=4" width="230px" >](https://github.com/nemzeet) |[<img src="https://avatars.githubusercontent.com/u/64514522?v=4" width="230" >](https://github.com/rlathgml1004)|
|:---:|:---:|:---:|:---:|
|ğŸ‘‘[ë°•í˜•ë¹ˆ](https://github.com/iDolphin99) |[ì¡°ìœ¤ë¹ˆ](https://github.com/yoonbincho) |[ë‚¨ì§€ìˆ˜](https://github.com/nemzeet)| [ê¹€ì†Œí¬](https://github.com/rlathgml1004)|
