{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d7d438",
   "metadata": {},
   "source": [
    "# 1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats #Analysis \n",
    "from scipy.stats import norm # Analysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams\n",
    "\n",
    "#지우기!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import special, optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트가 깨지면 실행하세요! \n",
    "import matplotlib.font_manager as fm\n",
    "fontlist = fm.findSystemFonts(fontpaths = None, fontext='ttf')\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "font_path=\"C:/Windows/Fonts/H2HDRM.TTF\"\n",
    "font=font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font',family=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/sohee/Desktop/KW/산학연계(졸작)/산학졸작_openUP_Data/kwproja_data_big.csv\",encoding='utf-8')\n",
    "data.head() # original data -> data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eecf56c",
   "metadata": {},
   "source": [
    "# EDA \n",
    "\n",
    "2,927,739 rows X 9 columns\n",
    "\n",
    "- 매장 속성 정보\n",
    "  - shop_code -> 식별자 feature, input feature로는 사용하지 않지만 분류를 위해서는 사용할 수 있을 것 같음  \n",
    "  - shop_name -> input feature로는 사용하지 않음 (NLP deep learning 가능성 있음)\n",
    "  - longtitude : 경도, latitude : 위도 -> 매장 위치 (회사 근처, 학교 근처 등 매출 영향성 있음) -> 군집화, labeling 필요\n",
    "  - shop_type_big -> 15 category  -> 업종 (매출 영향성 있음)\n",
    "  - shop_type_small -> 61 category\n",
    "\n",
    "- 매출 정보\n",
    "  - date -> 24 category, 201606~ 201805 까지의 data\n",
    "  - monthly_gain / avearge_sale_price = 한달 총 판매수\n",
    "\n",
    "- 매출 통계 정보-> X\n",
    "\n",
    "\n",
    "##### monthly_gain과 average_sale_price 중 어느 것을 y값으로 둘 것인가? \n",
    "- 월매출 예측 문제로 가정하고 montly_gain 을 y값으로 예측하는 모델 만들기\n",
    "\n",
    "##### shop_code는 input feature에 넣어야 하는가?\n",
    "- 특별한 브랜드가 y값을 결정하는 과적합 요소가 될 수 있으므로\n",
    "- X 에서 shop code, shop name 제외하는 것도 방법\n",
    "- 어느 위치에 어떤 업종으로 어떤 객단가인 매장을 오픈하면 월매출이 어떻게 될까? 문제\n",
    " - X: shop type big, shop type small, longitude, latitude, avg_sale_price, \n",
    " - y: montly_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c9722",
   "metadata": {},
   "source": [
    "# 3. Preprocessing\n",
    "- missing value 제거 \n",
    "    - monthly_gain : 3,605 제거 -> 149,790\n",
    "    - shop_type_big : 4,303 제거 -> 145,487 \n",
    "    - gender feature : 1,187 제거 -> 144,300\n",
    "- shop_code, shop_name : 식별자 feature 이므로 drop \n",
    "- date : 아직은 쓸 수 없으므로 drop\n",
    "    - 여기까지 총 144,300 X 27\n",
    "- shop_type_big(13), shop_type_small(367) : label encodding\n",
    "- longitude, latitude : clustering을 통해 labeling 후 해당 두 열은 drop \n",
    "- MinMaxSaclar 정규화 -> 정규화 column의 범위는??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 data와 따로 관리 -> original data = data, input data = input_data \n",
    "# feature drop\n",
    "input_data = data.copy()\n",
    "input_data = input_data.drop(['date', 'shop_code', 'shop_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad35fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There are no missing values \n",
    "# missing value drop - monthly_gain\n",
    "null_index = input_data[input_data['monthly_gain']==0].index \n",
    "print(len(null_index)) \n",
    "input_data = input_data.drop(null_index)\n",
    "\n",
    "# missing value drop - shop_type_big\n",
    "null_index = input_data[input_data['shop_type_big'].isnull()==True].index\n",
    "input_data = input_data.drop(null_index)\n",
    "\n",
    "# There is no \"null\" in \"shop_type_small\" feature \n",
    "print(len(input_data['shop_type_small'].unique()))\n",
    "print(input_data['shop_type_small'].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "input_data['shop_type_big'] = le.fit_transform(list(input_data['shop_type_big']))   # fit transform으로 한번에 처리 가능\n",
    "#le.classes_\n",
    "\n",
    "le = LabelEncoder()\n",
    "input_data['shop_type_small'] = le.fit_transform(list(input_data['shop_type_small'])) \n",
    "#le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236323b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling - KMeans Clustering \n",
    "# longitude + latitude = geo \n",
    "# So we get inpute_data = 144,300 X 27\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=9).fit(input_data[['latitude', 'longitude']])\n",
    "print(kmeans.cluster_centers_)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "# longitude + latitude = geo \n",
    "# So we get inpute_data = 2,927,739 rows × 5 columns\n",
    "input_data['geo'] = kmeans.labels_\n",
    "\n",
    "sns.scatterplot(x='longitude' , y='latitude', hue=\"geo\", data=input_data, palette=\"Paired\")\n",
    "plt.title('k-mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcbd73d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_data = input_data.drop(['longitude', 'latitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_sale_price -> skewed 된 feature \n",
    "# log정규화 \n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, Normalizer\n",
    "\n",
    "scale_cols = ['average_sale_price']\n",
    "\n",
    "for _ in scale_cols : \n",
    "    scaled_data = pd.DataFrame(np.log1p(input_data[_]))\n",
    "    input_data[_] = scaled_data\n",
    "\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rcParams['figure.figsize'] = 15,8\n",
    "#sns.boxplot(x='shop_type_big', y='average_sale_price', data=input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31684a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = plt.subplots()\n",
    "#ax = sns.distplot(input_data['monthly_gain'], hist=False)\n",
    "#ax.set_title('Total Gain Density')\n",
    "#ax.set_xlabel('Monthly Gain')\n",
    "#ax.set_ylabel('Unit Probability')\n",
    "#print(input_data['monthly_gain'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d58240",
   "metadata": {},
   "source": [
    "# 4. 타겟변수 확인\n",
    "why(or when) to use log transform in ML? \n",
    "- target variable이 non-negative values 일때만 \n",
    "- outlier 값들도 사용해야 하는 경우, outliers that can't be filtered out as they are important to the model.\n",
    "- 현재 주어진 data도 좌측으로 치우쳐진 (right skewed) 형태, 굉장히 극소수의 업종들만이 굉장히 큰 매출을 만들어낼 수 있는 것으로 보임 \n",
    "- 어떤 column, feature가 가장 monthly_gain과 상관관계가 높을까요? \n",
    "- kaggle house price prediction 대회에서도 RMSE가 아닌 RMSLE를 사용함 -> log를 씌운 형태인데 target variable인 집값의 범위가 넒기 때문\n",
    "\n",
    "- Skewness: The longer the right tail, the more positive the tail\n",
    "- Kurtosis (kurtosis / kurtosis): If the kurtosis value (K) is close to 3, the scatter is close to the normal distribution. (K <3), the distributions can be judged to be flattened more smoothly than the normal distribution, and if the kurtosis is a positive number larger than 3 (K> 3), the distribution can be considered to be a more pointed distribution than the normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f828869",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % input_data['monthly_gain'].skew())\n",
    "print(\"Kurtosis: %f\" % input_data['monthly_gain'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots=pd.DataFrame()\n",
    "plots['original']=input_data['monthly_gain']\n",
    "plots['transformed']=np.log1p(input_data['monthly_gain'])\n",
    "plots['backToOriginal']=np.expm1(np.log1p(input_data['monthly_gain']))\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "sns.distplot(plots['original'], ax=ax[0]);\n",
    "sns.distplot(plots['transformed'], ax=ax[1]);\n",
    "sns.distplot(plots['backToOriginal'], ax=ax[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,10))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "res = stats.probplot(input_data['monthly_gain'], plot=plt)\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "res = stats.probplot(np.log1p(input_data['monthly_gain']), plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55412fa2",
   "metadata": {},
   "source": [
    "# 5. Modeling\n",
    "- XGB (K-Fold Cross Validation (k=5))\n",
    "    - 타겟변수 정규화 실행 \n",
    "- LGBM (K-Fold Cross Validation (k=5))\n",
    "    - loss parameter : tweedie \n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80db5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas option 설정 하는 코드\n",
    "# monthly_gain의 경우 부동소수점으로 나타나서 보기 어려울땐 윗 줄의 주석을 제거하고 아래에 주석을 추가하고\n",
    "# 다시 원래대로 돌리고 싶다면 아래에 주석제거, 위에 주석추가\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "#pd.reset_option('display.float_format')\n",
    "\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_y = input_data['monthly_gain'].copy()\n",
    "input_data_X = input_data.drop(['monthly_gain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ec416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, TimeSeriesSplit,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import plot_importance \n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    input_data_X, \n",
    "    input_data_y, \n",
    "    test_size = 0.2,      \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046875e",
   "metadata": {},
   "source": [
    "#### 5.1 XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f90cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_kfold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state = 7)\n",
    "cv_accuracy = []\n",
    "n_iter =0\n",
    "\n",
    "for train_index, valid_index in kfold.split(train_X):  # 데이터를 kfold = 5 로 분할\n",
    "    x_train, x_valid = train_X.iloc[list(train_index)], train_X.iloc[list(valid_index)]\n",
    "    y_train, y_valid = train_y.iloc[list(train_index)], train_y.iloc[list(valid_index)]\n",
    "    #y_train, y_valid = np.log1p(y_train), np.log1p(y_valid)\n",
    "\n",
    "    model_xgb.fit(x_train, y_train)\n",
    "    pred = model_xgb.predict(x_valid)\n",
    "    n_iter += 1\n",
    "    \n",
    "    mse = np.round(mean_squared_error(y_valid, pred), 4) # 소수점 4자리 반올림\n",
    "    rmse = np.sqrt(mse)\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_valid.shape[0]\n",
    "    \n",
    "    print('\\n#{0} 교차 검증 rmse : {1},  학습 데이터 크기 : {2},  검증 데이터 크기 : {3}'\n",
    "          .format(n_iter, rmse, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter,valid_index))\n",
    "    cv_accuracy.append(rmse)\n",
    "    \n",
    "print('\\n## 평균 검증 rmse:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dee2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb = model_xgb.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cdd4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_xgb = np.exp(pred_xgb)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0795f79e",
   "metadata": {},
   "source": [
    "#### 5.2 LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': [7, 14, 21, 28, 31, 50],\n",
    "    'learning_rate': [0.1, 0.03, 0.003],\n",
    "    'max_depth': [-1, 3, 5],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abb14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = LGBMRegressor(random_state=0, n_jobs=-1)\n",
    "lgbm_grid = GridSearchCV(model_lgbm,params, cv=5, n_jobs=4)\n",
    "lgbm_grid.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5414394",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best=LGBMRegressor(n_estimators=500, num_leaves=50, \n",
    "                        random_state=0,learning_rate=0.1,max_depth=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_kfold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state = 7)\n",
    "cv_accuracy = []\n",
    "n_iter =0\n",
    "\n",
    "for train_index, valid_index in kfold.split(train_X):  # 데이터를 kfold = 5 로 분할\n",
    "    x_train, x_valid = train_X.iloc[list(train_index)], train_X.iloc[list(valid_index)]\n",
    "    y_train, y_valid = train_y.iloc[list(train_index)], train_y.iloc[list(valid_index)]\n",
    "    #y_train, y_valid = np.log1p(y_train), np.log1p(y_valid)\n",
    "    \n",
    "    lgbm_best.fit(x_train, y_train)\n",
    "    pred = lgbm_best.predict(x_valid)\n",
    "    n_iter += 1\n",
    "    \n",
    "    mse = np.round(mean_squared_error(y_valid, pred), 4) # 소수점 4자리 반올림\n",
    "    rmse = np.sqrt(mse)\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_valid.shape[0]\n",
    "    \n",
    "    print('\\n#{0} 교차 검증 rmse : {1},  학습 데이터 크기 : {2},  검증 데이터 크기 : {3}'\n",
    "          .format(n_iter, rmse, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter,valid_index))\n",
    "    cv_accuracy.append(rmse)\n",
    "    \n",
    "print('\\n## 평균 검증 rmse:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgbm = lgbm_best.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_lgbm = np.exp(pred_lgbm)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20421f41",
   "metadata": {},
   "source": [
    "#### 5.3 Random Forest (+hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params ={\n",
    "#    'n_estimators':[100],\n",
    "#    'max_depth':[6,8,10,12],\n",
    "#    'min_samples_leaf':[8,12,18],\n",
    "#    'min_samples_split':[8,16,20]\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4011f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 parameter를 찾기위한 학습\n",
    "#rf = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "#grid_cv = GridSearchCV(rf, param_grid=params, cv=2, n_jobs=-1)\n",
    "#grid_cv.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8975547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 parameter\n",
    "#grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_best=RandomForestRegressor(max_depth=12, min_samples_leaf=8, \n",
    "                              min_samples_split=8,n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state = 7)\n",
    "cv_accuracy = []\n",
    "n_iter =0\n",
    "\n",
    "for train_index, valid_index in kfold.split(train_X):  # 데이터를 kfold = 5 로 분할\n",
    "    x_train, x_valid = train_X.iloc[list(train_index)], train_X.iloc[list(valid_index)]\n",
    "    y_train, y_valid = train_y.iloc[list(train_index)], train_y.iloc[list(valid_index)]\n",
    "    #y_train, y_valid = np.log1p(y_train), np.log1p(y_valid)\n",
    "\n",
    "    model_rf_best.fit(x_train, y_train)\n",
    "    pred = model_rf_best.predict(x_valid)\n",
    "    n_iter += 1\n",
    "    \n",
    "    mse = np.round(mean_squared_error(y_valid, pred), 4) # 소수점 4자리 반올림\n",
    "    rmse = np.sqrt(mse)\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_valid.shape[0]\n",
    "    \n",
    "    print('\\n#{0} 교차 검증 rmse : {1},  학습 데이터 크기 : {2},  검증 데이터 크기 : {3}'\n",
    "          .format(n_iter, rmse, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter,valid_index))\n",
    "    cv_accuracy.append(rmse)\n",
    "    \n",
    "print('\\n## 평균 검증 rmse:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf=model_rf_best.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201440a",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    #hist = pd.DataFrame(history.history)\n",
    "    #history['epoch'] = history.epoch\n",
    "    \n",
    "    plt.figure(figsize=(8,12))\n",
    "    \n",
    "    # Mean Abs Error : 평균 절대 오차, 측정값에서 오차의 크기로 측정값과 실제값과의 차이, 절대 오차의 평균  \n",
    "    # -> 측정하고자 하는 값을 정확하게 측정하지 못함으로써 발생\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Mean Square Error : 평균 제곱 오차, 오차의 제복에 대한 평균을 취한 값\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "    plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def show_pred(test_y, pred) :\n",
    "    true_y = test_y.to_numpy()\n",
    "    true_y = np.ravel(true_y)\n",
    "    \n",
    "    df_result = pd.DataFrame(list(zip(true_y, pred)), columns=['true_y', 'prediction'])\n",
    "    return df_result\n",
    "\n",
    "def show_mse_rmse(test_y, pred) :\n",
    "    mse = mean_squared_error(test_y, pred)\n",
    "    print(\"mse : %f\" % mse)\n",
    "    \n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"rmse: %f \\n\" %rmse)\n",
    "    \n",
    "def show_prediction_error(test_y, pred) :\n",
    "    true_y = test_y.to_numpy()\n",
    "    true_y = np.ravel(true_y)\n",
    "    error = pred - true_y\n",
    "    plt.hist(error, bins=25)\n",
    "    plt.xlabel(\"Prediction Error\")\n",
    "    _ = plt.ylabel(\"Count\")\n",
    "    \n",
    "def feature_importance(model_xgb) : \n",
    "    %matplotlib inline\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    font_path = \"C:/Windows/Fonts/NGULIM.TTF\"\n",
    "    font = fm.FontProperties(fname=font_path).get_name()\n",
    "    rc('font', family=font)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,12))\n",
    "    plot_importance(model_xgb, ax=ax)\n",
    "    \n",
    "def graph(pred, test_label) :\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.plot(test_label, label = 'actual')\n",
    "    plt.plot(pred, label = 'prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pred(test_y, pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pred(test_y, pred_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0708a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pred(test_y, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89def36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_mse_rmse(test_y, pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7fb22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_mse_rmse(test_y, pred_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9264e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_mse_rmse(test_y, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17960bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_y = test_y.to_numpy()\n",
    "#graph(pred_xgb, true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(17,7))\n",
    "#plt.plot(range(0, len(test_y)), test_y,'o-', label='Actual Value')\n",
    "#plt.plot(range(0, len(pred_xgb)), pred_lgbm, '-', label='Predict Value')\n",
    "#plt.title('Prediction of Monthly Gain')\n",
    "#plt.ylabel('Monthly gain')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756228fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_series = pd.Series(data=model_xgb.feature_importances_, index=train_X.columns)\n",
    "#feature_series = feature_series.sort_values(ascending=False) \n",
    "#sns.barplot(x = feature_series, y=feature_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b062d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_series = pd.Series(data=model_lgbm.feature_importances_, index=train_X.columns)\n",
    "#feature_series = feature_series.sort_values(ascending=False) \n",
    "#sns.barplot(x = feature_series, y=feature_series.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
